{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os.path as osp\n",
    "import time\n",
    "from torchmetrics.functional import retrieval_average_precision,retrieval_normalized_dcg\n",
    "import pandas as pd\n",
    "def vectorize_sort(x, permutation):\n",
    "    # Order tensor by indecis\n",
    "    d1, d2 = x.size()\n",
    "    ret = x[\n",
    "        torch.arange(d1).unsqueeze(1).repeat((1, d2)).flatten(),\n",
    "        permutation.flatten(),\n",
    "    ].view(d1, d2)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/kbibas/code/fbt_research/outputs/train_cycle_with_clf_Clothing_Shoes_and_Jewelry_20220708_192523/src.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kbibas/code/fbt_research/notebooks/eval.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000001?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Users/kbibas/code/fbt_research/outputs/train_cycle_with_clf_Clothing_Shoes_and_Jewelry_20220708_192523\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000001?line=1'>2</a>\u001b[0m src \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(osp\u001b[39m.\u001b[39;49mjoin(path,\u001b[39m'\u001b[39;49m\u001b[39msrc.pth\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000001?line=2'>3</a>\u001b[0m src_fbt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(osp\u001b[39m.\u001b[39mjoin(path,\u001b[39m'\u001b[39m\u001b[39msrc_fbt.pth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000001?line=3'>4</a>\u001b[0m asin_src \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(osp\u001b[39m.\u001b[39mjoin(path,\u001b[39m'\u001b[39m\u001b[39masin_src.pth\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/fbt_research/lib/python3.10/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/fbt_research/lib/python3.10/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/fbt_research/lib/python3.10/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/kbibas/code/fbt_research/outputs/train_cycle_with_clf_Clothing_Shoes_and_Jewelry_20220708_192523/src.pth'"
     ]
    }
   ],
   "source": [
    "path = '/Users/kbibas/code/fbt_research/outputs/train_cycle_with_clf_Clothing_Shoes_and_Jewelry_20220708_192523'\n",
    "src = torch.load(osp.join(path,'src.pth'))\n",
    "src_fbt = torch.load(osp.join(path,'src_fbt.pth'))\n",
    "asin_src = torch.load(osp.join(path,'asin_src.pth'))\n",
    "candidates_order  = torch.load(osp.join(path,'candidates_order.pth'))\n",
    "category_int_src_test = torch.load(osp.join(path,'category_int_src_test.pth'))\n",
    "category_int_pos_test = torch.load(osp.join(path,'category_int_pos_test.pth'))\n",
    "hot_label_test = torch.load(osp.join(path,'hot_label_test.pth'))\n",
    "set_name = torch.load(osp.join(path,'set_name.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fbt_test = src_fbt[set_name=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_val=0.65279 rmap_val=0.00952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kbibas/code/fbt_research/notebooks/eval.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000002?line=11'>12</a>\u001b[0m \u001b[39m# TopK\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000002?line=12'>13</a>\u001b[0m t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000002?line=13'>14</a>\u001b[0m _, sort_idxs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msort(dists, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000002?line=14'>15</a>\u001b[0m is_true \u001b[39m=\u001b[39m vectorize_sort(hot_label_test, sort_idxs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kbibas/code/fbt_research/notebooks/eval.ipynb#ch0000002?line=15'>16</a>\u001b[0m topk_d \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Find distance of the candidates\n",
    "t2 = time.time()\n",
    "dists = torch.cdist(src_fbt_test, candidates_order, p=2)\n",
    "probs = torch.softmax(-dists, axis=-1)\n",
    "\n",
    "# Calculate mAP\n",
    "t2 = time.time()\n",
    "rmap_val = retrieval_average_precision(probs, hot_label_test).item()\n",
    "ndcg_val =  retrieval_normalized_dcg(probs, hot_label_test).item()\n",
    "print(f'{ndcg_val=:.5f} {rmap_val=:.5f}')\n",
    "\n",
    "# TopK\n",
    "t2 = time.time()\n",
    "_, sort_idxs = torch.sort(dists, dim=-1)\n",
    "is_true = vectorize_sort(hot_label_test, sort_idxs)\n",
    "topk_d = {}\n",
    "top_k = [1,3,5,10]\n",
    "for k in top_k:\n",
    "    topk = torch.any(is_true[:, :k], axis=-1).float().mean().item()\n",
    "print(f'{topk_d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fbt_research')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68c3785b6d0d69f32ec3345cc9370452c1107ed7cec67c0016e6c2bd7219956e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
